# Story UI Configuration
# Copy this file to .env and configure your API keys

# =============================================================================
# LLM Provider API Keys
# =============================================================================
# Configure one or more providers. Story UI will use the first available.

# Claude (Anthropic)
# Get your API key from: https://console.anthropic.com/
CLAUDE_API_KEY=your-claude-api-key
# Alternative key name also supported:
# ANTHROPIC_API_KEY=your-claude-api-key

# OpenAI
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key
# Optional: Organization ID for team accounts
# OPENAI_ORG_ID=your-org-id

# Google Gemini
# Get your API key from: https://aistudio.google.com/apikey
GEMINI_API_KEY=your-gemini-api-key
# Alternative key name also supported:
# GOOGLE_API_KEY=your-gemini-api-key

# =============================================================================
# Default Model Selection
# =============================================================================
# These settings define the default provider and model for story generation.

# Default LLM provider (claude, openai, gemini)
DEFAULT_PROVIDER=claude

# Default model ID
# Claude models:
#   claude-opus-4-5-20251101   - Most capable, highest quality
#   claude-sonnet-4-5-20250514 - Great balance of speed and quality (recommended)
#   claude-3-7-sonnet-20250219 - Fast and efficient
#   claude-3-5-haiku-20241022  - Fastest, good for simple tasks
# OpenAI models:
#   gpt-5.1                    - Latest GPT-5 with adaptive reasoning
#   gpt-5.1-thinking           - Extended thinking for complex tasks
#   gpt-5                      - Original GPT-5
#   gpt-4o                     - Fast multimodal (recommended)
#   gpt-4o-mini                - Budget option
#   o1                         - Reasoning model
# Gemini models:
#   gemini-3-pro               - Most intelligent Gemini (recommended)
#   gemini-2.0-flash           - Fast and efficient
#   gemini-1.5-pro             - Legacy, large context
DEFAULT_MODEL=claude-sonnet-4-5-20250514

# Legacy model config (still supported):
# CLAUDE_MODEL=claude-sonnet-4-20250514
# OPENAI_MODEL=gpt-4o
# GEMINI_MODEL=gemini-2.0-flash

# =============================================================================
# DevOps Guardrails (Optional)
# =============================================================================
# These settings restrict which providers and models users can select in the UI.
# Useful for enterprise deployments or cost control.

# Allowed providers (comma-separated)
# If not set, all configured providers are available
# ALLOWED_PROVIDERS=claude,openai,gemini

# Allowed models (comma-separated)
# If not set, all models from allowed providers are available
# ALLOWED_MODELS=claude-sonnet-4-5-20250514,gpt-4o,gemini-2.0-flash

# Single provider mode - hide provider selection in UI
# Set to 'true' to lock users to the default provider
# SINGLE_PROVIDER_MODE=false

# =============================================================================
# Server Configuration
# =============================================================================

# MCP server port (default: 4001)
# PORT=4001

# Production mode - use in-memory story storage
# STORY_UI_PRODUCTION=true

# CORS allowed origins (comma-separated) for external access
# STORY_UI_ALLOWED_ORIGINS=https://your-domain.com,https://storybook.your-domain.com

# Optional: Custom config file path
# STORY_UI_CONFIG_PATH=./story-ui.config.js
